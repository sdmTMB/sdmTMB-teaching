---
title: "Fitting a spatiotemporal model"
format: html
editor: visual
execute: 
  echo: true
  eval: true
---

# Goals:

-   Practice fitting a basic spatiotemporal model.
-   Gain experience using cross validation for model selection.
-   Gain experience with anistropy.
-   Understand how to inspect the model output.
-   Practice predicting from the model on new data and making visualizations of those predictions.
-   Gain familiarity with fitting and interpreting different random field structures.
-   Try fitting a spatially varying coefficient model.

```{r, message=FALSE, warning=FALSE}
#| echo=FALSE
library(sdmTMB)
library(dplyr)
library(ggplot2)
library(inlabru)
library(purrr)
options(ggplot2.continuous.colour = "viridis")
options(ggplot2.continuous.fill = "viridis")
theme_set(theme_light())
```

# The data

We will work with data representing North Pacific Spiny Dogfish in the West Coast Vancouver Island synoptic trawl survey.

```{r}
dat <- readRDS(here::here("dfo-tesa-2025/data/wcvi-dogfish.rds"))
```

```{r}
head(dat)
```

The dataset contains sampling locations (`longitude` and `latitude`) and `year`. It also contains sampling `depth` in meters and sample density `density` (CPUE) in units of tonnes/km^2^.

```{r}
ggplot(dat, aes(longitude, latitude, size = density)) + geom_point()
```

# Adding UTMs

We can add UTM columns using `add_utm_columns()`:

```{r}
add_utm_columns(dat, ll_names = c("longitude", "latitude"))
```

Note that this function guesses at an appropriate UTM projection for you and provides a URL to verify. To ensure future compatibility with prediction grids or other data, it is best to hard code the choice using the `utm_crs` argument. We will use `CRS = 3156` here to match our prediction grid:

```{r}
dat <- add_utm_columns(dat, utm_crs = 3156, ll_names = c("longitude", "latitude"))
```

And check to make sure that looks right:

```{r}
ggplot(dat, aes(X, Y, size = density)) + geom_point(shape = 21) + coord_fixed()
```

We can also plot the data by year:

```{r}
ggplot(dat, aes(X, Y, size = density, colour = log(density + 1))) +
  geom_point(alpha = 0.3) +
  facet_wrap(~year) + coord_fixed()
```

We will create these new columns to use later:

```{r}
dat$log_depth <- log(dat$depth)
dat$year_factor <- as.factor(dat$year)
```

# Constructing a mesh

We start by constructing an SPDE mesh with fmesher. This creates some matrices that are used internally when fitting the model. We will use the shortcut function `make_mesh()` and use a cutoff (minimum triangle length of 10 km).

```{r}
mesh <- make_mesh(dat, xy_cols = c("X", "Y"), cutoff = 10)
plot(mesh)
mesh$mesh$n # number of vertices or knots

# ggplot alternative:
ggplot() + inlabru::gg(mesh$mesh) + coord_fixed() +
  geom_point(aes(X, Y), data = dat, alpha = 0.2, size = 0.5)
```

### Exercise:

1.  Try adjusting the size of the cutoff distance to explore the effects of decreasing the mesh resolution. Make sure to reset the `cutoff` value to `10` in the end so the rest of the exercise behaves as intended, because model convergence issues can be caused by meshes that are either too fine or too coarse.

# Fitting a spatial model

The most basic model we could fit would be a model with a single spatial random field, and no covariates. We fit that yesterday. Here, we will introduce a depth covariate.

Using `silent = FALSE` lets us see what is happening, but it's awkward when running code in Rmd/Quarto chunks (with the default RStudio setting to 'Show output inline for all R Markdown document') so we will comment it out in most cases here. But it is a good idea to use it if models are running slowly or not converging to monitor progress.

```{r, results='hide'}
fit_spatial <- sdmTMB(
  density ~ poly(log_depth, 2), # quadratic depth effect
  data = dat,  
  family = tweedie(link = "log"),
  mesh = mesh,
  spatial = "on",
  # silent = FALSE
)
```

```{r}
sanity(fit_spatial)
```

```{r}
fit_spatial
```

### Exercise:

A refresher from yesterday:

1.  What is the 'Matern range' in the output?
2.  What is the 'Spatial SD' in the output?
3.  What is the 'Dispersion parameter' in the output?

# Anisotropy and cross validation

We can consider whether including anisotropy improves model predictions. This lets the correlation decay differently depending on direction.

First, let's fit out possible anisotropic model to make sure it can be estimated:

```{r}
fit_aniso <- sdmTMB(
  density ~ poly(log_depth, 2), # quadratic depth effect
  data = dat,  
  family = tweedie(link = "log"),
  mesh = mesh,
  spatial = "on",
  anisotropy = TRUE
)
```

Anisotropic range is best examined graphically:

```{r}
plot_anisotropy(fit_aniso)
```

## Exercise:

1.  What is this plot showing? See `?plot_anisotropy`
2.  Does this make sense here? Think about the geography of west coast of Vancouver Island.

AIC would be one way to compare models but is not ideal when we're dealing with mixed effects models---particularly when the random effects are contributing substantially to our predictions.

We can check the AIC of the 2 models:

```{r}
AIC(fit_spatial, fit_aniso)
```

We will demonstrate cross validation using the built-in `sdmTMB_cv()` function. As a refresher for cross validation:

1.  The data are divided into `k` folds
2.  In turn, each fold is used as the test or validation dataset, with the remaining data used to fit the model
3.  Measures of predictive accuracy are calculated for each fold, and finally across the full dataset
4.  The number of folds, and how folds are selected can affect results
5.  We can manually set the folds if we'd like. Here will divide the data by year.

```{r}
# optional for parallel processing
library(future)
plan(multisession)

dat$folds <- as.numeric(factor(dat$year))
unique(dat$folds)

cv_anisotropic <- sdmTMB_cv(
  density ~ poly(log_depth, 2),
  data = dat,  
  spatial = "on",
  anisotropy = TRUE, #<
  family = tweedie(),
  fold_ids = dat$folds,
  mesh = mesh
)

cv_isotropic <- sdmTMB_cv(
  density ~ poly(log_depth, 2),
  data = dat,  
  spatial = "on",
  family = tweedie(),
  fold_ids = dat$folds,
  mesh = mesh,
)
```

These are the log predictive densities for each fold. Larger (more positive) values are better. This gives us an idea of the variance of these values across folds.

```{r}
cv_anisotropic$fold_loglik
cv_isotropic$fold_loglik

# check each fold between the two models:
cv_anisotropic$fold_loglik - cv_isotropic$fold_loglik
```

These are the expected log predictive densities for all left-out data combined.

```{r}
cv_anisotropic$sum_loglik
cv_isotropic$sum_loglik
```

We could look at the standard error on the difference across folds as one way to assess whether this is a meaningful difference.

```{r}
cv_results <- data.frame(
  model = rep(c("anisotropic", "isotropic"), each = length(unique(dat$folds))),
  loglik = c(cv_anisotropic$fold_loglik, cv_isotropic$fold_loglik)
)

cv_results |>
  group_by(model) |>
  summarise(
    sum_loglik = sum(loglik),
    se = sqrt(n()) * sd(loglik)
  )

# Difference in sum log-likelihood with SE
lpd_diff <- cv_anisotropic$sum_loglik - cv_isotropic$sum_loglik
se_diff <- sqrt(8) * sd(cv_anisotropic$fold_loglik - cv_isotropic$fold_loglik)
cat("LPD difference (anisotropic - isotropic):", round(lpd_diff, 2), "Â±", round(se_diff, 2), "\n")
```

### Exercise:

1.  Which model does LPD suggest has better out-of-sample predictive performance?
2.  How consistent is that result across folds?
3.  We assigned folds. What happens if you don't do this? Why might you want to set the random seed first?
4.  How else could you use the folds?

We won't dwell on this model here for the sake of time, but in practice we would stop, inspect, and understand this model before progressing to a spatiotemporal model.

# Fitting a model with spatial + spatiotemporal fields

This first model includes a quadratic effect of log depth (`poly(log_depth, 2)`), a factor effect for each year, and models total density using a Tweedie distribution and a log link. The spatial field and spatiotemporal fields are estimated.

The year factors give each year its own mean (this is generally the approach used in fisheries stock assessment). The `0 +` omits the intercept such that each year's estimate represents a mean as opposed to a difference from the intercept. This part is arbitrary and chosen for the sake of this exercise.

The choice to use log depth helps the model fit because we have fewer samples from the deeper depths.

```{r, results='hide'}
fit <- sdmTMB(
  density ~ 0 + year_factor + poly(log_depth, 2),
  data = dat,
  family = tweedie(link = "log"),
  mesh = mesh,
  anisotropy = TRUE,
  spatial = "on",
  spatiotemporal = "iid", #< new
  time = "year", #< new
  # silent = FALSE
)
```

### Exercise:

1.  Skim the help file (`?sdmTMB`). What are the other options for `spatiotemporal`?

Print the model:

```{r}
fit
```

### Exercise:

1.  What is new in the output of `fit` compared to `fit_spatial`?

Run a basic sanity check on the model:

```{r}
sanity(fit)
```

We can use the tidy function to get the coefficients for the fixed effects:

```{r}
tidy(fit, conf.int = TRUE)
```

and by setting `effects = "ran_pars"`, we can extract the variance and random effect components:

```{r}
tidy(fit, effects = "ran_pars", conf.int = TRUE)
```

There are multiple ways we can plot the depth effect on density. First, we can create a new data frame of all potential values, setting the other predictors (here year) to a fixed value.

```{r}
nd <- data.frame(log_depth = seq(log(50), log(700), length.out = 100), year = 2004)
# (picking any one year)
nd$year_factor <- as.factor(nd$year)

p <- predict(
  fit,
  newdata = nd,
  re_form = ~ 0, # means only include the fixed effects (not the default)
  se_fit = TRUE # means calculate standard errors (not the default)
)

ggplot(p, aes(log_depth, exp(est),
  ymin = exp(est - 1.96 * est_se), ymax = exp(est + 1.96 * est_se))) +
  geom_line() + geom_ribbon(alpha = 0.4)
```

The second approach is to pass the sdmTMB object to the visreg package. This shows the conditional effect, where all values other than depth are held at a particular value. Note the default visreg plot is in link (here, log) space and the dots are randomized quantile residuals.

```{r}
visreg::visreg(fit, xvar = "log_depth")
visreg::visreg(fit, xvar = "log_depth", scale = "response")
```

Third, we could use the `ggeffects` package, which can be used to show the marginal effects of predictors (averaging over all other covariates rather than using a single fixed value). For more details see the [visualizing marginal effects vignette](https://pbs-assess.github.io/sdmTMB/articles/ggeffects.html). *Note that this won't yet work with smoother `s()` terms*, but will work with the similar `ggeffects::ggpredict()` .

```{r}
g <- ggeffects::ggeffect(fit, "log_depth [3.5:6.7 by=0.05]")
plot(g)
```

# Prediction

Let's now predict on a grid that covers the entire survey (`wcvi_grid`).

```{r}
wcvi_grid <- readRDS(here::here("dfo-tesa-2023/data/wcvi-grid.rds"))
head(wcvi_grid)
wcvi_grid$log_depth <- log(wcvi_grid$depth)
```

We can use this fancy line of purrr code to expand our grid to every year we want to predict on:

```{r}
grid <- sdmTMB::replicate_df(wcvi_grid, "year", unique(dat$year))
grid$year_factor <- as.factor(grid$year)
head(grid)
```

We can predict on the original data:

```{r}
p0 <- predict(fit)
```

To predict on a new data frame, we can specify `newdata`. Here, we will predict on the survey grid. (1) This makes it easy to make visualizations. (2) This will be useful if we wanted to generate an area-weighted standardized population index later.

```{r}
p <- predict(fit, newdata = grid)
```

We can plot each of the components of the prediction data frame spatially:

```{r}
# Depth and year effect contribution:
# (Everything not a random field)
ggplot(p, aes(X, Y, fill = exp(est_non_rf))) +
  facet_wrap(~year) +
  geom_raster() +
  coord_fixed()

# Spatial random field:
ggplot(p, aes(X, Y, fill = omega_s)) +
  facet_wrap(~year) +
  geom_raster() +
  scale_fill_gradient2() +
  coord_fixed()

# Spatial-temporal random field:
ggplot(p, aes(X, Y, fill = epsilon_st)) +
  facet_wrap(~year) +
  geom_raster() +
  scale_fill_gradient2() +
  coord_fixed()

# Overall estimate of density in link (log) space:
ggplot(p, aes(X, Y, fill = est)) +
  facet_wrap(~year) +
  geom_raster() +
  coord_fixed()

# Overall estimate of density: (with log-distributed colour)
ggplot(p, aes(X, Y, fill = exp(est))) +
  facet_wrap(~year) +
  geom_raster() +
  coord_fixed() +
  scale_fill_viridis_c(trans = "log10")
```

### Exercise:

1.  Step through each of the plots above and discuss what each represents.

# Residual checking

We can calculate randomized quantile residuals with the `residuals.sdmTMB()` function.

```{r}
dat$resid <- residuals(fit, type = "mle-mvn")
```

We can plot those residuals spatially:

```{r}
ggplot(dat, aes(X, Y, colour = resid)) +
  facet_wrap(~year) +
  geom_point(size = 0.5) +
  coord_fixed() +
  scale_colour_gradient2()
```

## Exercise:

1.  What are you looking for in the above? Does it look OK?
2.  Usually visual inspection is fine but what kind of formal test could you use for spatial correlation?

We can check the distribution of the residuals with a QQ plot:

```{r}
qqnorm(dat$resid)
qqline(dat$resid)
```

There's a whole vignette on residual checking with sdmTMB here: <https://pbs-assess.github.io/sdmTMB/articles/residual-checking.html>

We can simulate new observations from the model and check properties of the simulation compared to the observed data:

```{r}
set.seed(1)
s <- simulate(fit, nsim = 200, type = "mle-mvn")
```

```{r}
mean(s == 0)
mean(dat$density == 0)
```

```{r}
hist(s, xlim = c(0, 30), breaks = 200, freq = FALSE)
hist(dat$density, xlim = c(0, 30), breaks = 200, freq = FALSE)
```

We could also use these with the DHARMa package:

```{r}
dharma_residuals(s, fit)
```

## Exercise:

1.  What is the difference between `sdmTMB_simulate()` and `simulate.sdmTMB()`?

# Fitting an AR(1) fields model

An alternative model would use AR(1) (first order autoregressive) correlated fields with or without spatial fields.

```{r, results='hide', warning=FALSE, message=FALSE}
fit_ar1 <- update(
  fit, 
  spatial = "off", #< left of on purpose to illustrate something below; normally leave on
  spatiotemporal = "ar1"
)
```

```{r}
sanity(fit_ar1)
fit_ar1
```

```{r}
AIC(fit, fit_ar1)
```

```{r}
tidy(fit_ar1, "ran_pars", conf.int = TRUE)
```

## Exercise:

1.  What is the estimated random field AR(1) correlation value (`rho`)? (Hint: see `print(fit_ar1)` and the `tidy()` line above.)
2.  What does this mean? Does this make sense ecologically?
3.  What is a subtle reason why you might want to include spatial fields if you're using AR(1) fields? (Hint: think about the first time step and what the random field SD represents in the AR(1) process.)
4.  We didn't specify `extra_time` what are the implications of that?

Let's plot the predictions from our two models:

```{r}
p_iid <- predict(fit, newdata = grid)
p_ar1 <- predict(fit_ar1, newdata = grid)
```

We'll write a little helper function to make some plots:

```{r}
plot_field <- function(data, column_name, lims = NULL) {
  ggplot(data, aes(X, Y, fill = {{ column_name }})) +
    facet_wrap(~year, nrow = 1) +
    geom_raster() +
    scale_fill_gradient2(limits = lims) +
    coord_fixed()
}
```

And plot the spatiotemporal field estimates (`epsilon_st`) for 3 example years:

```{r}
yrs <- c(2012, 2014, 2016)
scale_limits <- range(c(p_iid$epsilon_st, p_ar1$epsilon_st))

g1 <- filter(p_iid, year %in% yrs) |> 
  plot_field(epsilon_st, lims = scale_limits) + 
  ggtitle("IID spatiotemporal fields")
g2 <- filter(p_ar1, year %in% yrs) |> 
  plot_field(epsilon_st, lims = scale_limits) + 
  ggtitle("AR1 spatiotemporal fields")

cowplot::plot_grid(g1, g2, nrow = 2, align = "v")
```

## Exercise:

1.  How do these differ given the assumptions of the models? Why don't they look the same?

What if we combine the spatial and spatiotemporal fields from the IID model?

```{r}
scale_limits <- range(c(p_iid$omega_s + p_iid$epsilon_st, p_ar1$epsilon_st))

g1 <- filter(p_iid, year %in% yrs) |> 
  plot_field(epsilon_st + omega_s, lims = scale_limits) + 
  ggtitle("Spatial + IID spatiotemporal fields")
g2 <- filter(p_ar1, year %in% yrs) |> 
  plot_field(epsilon_st, lims = scale_limits) + 
  ggtitle("AR1 spatiotemporal fields")

cowplot::plot_grid(g1, g2, nrow = 2, align = "v")
```

## Exercise:

1.  Do these look more similar than the previous plot? Why?

We'll make another little helper function to plot predictions:

```{r}
plot_map <- function(data, column_name, lims = NULL) {
  ggplot(data, aes(X, Y, fill = {{ column_name }})) +
    facet_wrap(~year) +
    geom_raster() +
    scale_fill_viridis_c(limits = lims) +
    coord_fixed()
}
```

And plot predictions from our 2 models:

```{r}
scale_limits <- range(c(p_iid$est, p_ar1$est))

g1 <- filter(p_iid, year %in% yrs) |>
  plot_map(est, lims = scale_limits) + 
  ggtitle("IID predictions")
g2 <- filter(p_ar1, year %in% yrs) |> 
  plot_map(est, lims = scale_limits) + 
  ggtitle("AR1 predictions")

cowplot::plot_grid(g1, g2, nrow = 2, align = "v")
```

### Exercise:

1.  How similar do the predictions look? Is there a big difference in the end?

2.  How could we pick between these models?

# Spatially varying coefficients

Let's try fitting a spatially varying coefficient (SVC) for year. If year is our covariate, we can interpret this as a local proportional change per year.

We'll start by (roughly) centering our year predictor to make it more computationally stable.

```{r}
dat$year_centered <- dat$year - 2012
fit_svc <- sdmTMB(
  density ~ year_centered,
  data = dat,  
  family = tweedie(link = "log"),
  mesh = mesh,
  spatial = "on",
  spatial_varying = ~ year_centered, #<
  # silent = FALSE
)

grid$year_centered <- grid$year - 2012
p_svc <- predict(fit_svc, newdata = grid)
ggplot(p_svc, aes(X, Y, fill = exp(est))) +
  geom_raster() +
  scale_fill_gradient2(trans = "log10") +
  coord_fixed()
```

## Exercise:

1.  What are we looking at and what does it mean?

# Bonus

## Exercise:

1.  We assumed the spatial/spatiotemporal range was shared between the 2 sets of fields. Try a version with `share_range = FALSE` (use `sdmTMB()` or `update()`).
2.  If working with the anisotropic version, try `plot_anisotropy()`. Otherwise, look at the range estimates in the model output.
3.  Is the range different between the spatial and spatiotemporal fields? Is that what you expected?
4.  Are either of the ranges smaller than the cutoff distance of your mesh? If so, why might you want to try a different mesh?

```{r, results='hide'}
fit2 <- sdmTMB(
  density ~ 0 + year_factor + poly(log_depth, 2),
  data = dat,
  family = tweedie(link = "log"),
  mesh = mesh,
  spatial = "on",
  spatiotemporal = "iid",
  time = "year",
  anisotropy = TRUE,
  # silent = FALSE,
  # share_range =   # exercise
)
# plot_anisotropy(fit2)
```

```{r}
sanity(fit2)
fit2
tidy(fit2, effects = "ran_pars", conf.int = TRUE)
```
